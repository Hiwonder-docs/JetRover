# 1. Quick Start Guide

## 1.1 JetRover Overview and Version Description

JetRover is a comprehensive ROS robot for ROS educational scenarios. Its chassis can be seamlessly switched between Mecanum-wheels chassis, tank chassis and Ackermann chassis.

The main controller supports Jetson Nano, Jetson Orin Nano, Jetson Orin NX and Raspberry Pi. Its chassis adopts an STM32 controller, and its body is armed with high-performance hardware such as Lidar, depth camera, microphone array, etc. It can enable mapping and navigation, path planning, human-machine interaction, autonomous driving, deep learning and voice interaction.

The packing list below uses Mecanum-wheel chassis as an example. Other accessories are applicable to all robot versions.

<img src="../_static/media/chapter_1/image4.png" class="common_img" />

<img src="../_static/media/chapter_1/image5.png" class="common_img" />



## 1.2 Hardware Installation and Setup

### 1.2.1 Depth Camera and Robot Arm Installation

* **Camera Bracket Installation**

(1) Fix 3D depth camera bracket to robot arm using M3*6 round-head machine screw.

<img src="../_static/media/chapter_1/image9.png" class="common_img" />

(2) Mount 3D depth camera to camera bracket with M3*6 round-head machine screw.

:::{Note}
The port of 3D depth camera is on robot's right side.
:::

<img src="../_static/media/chapter_1/image10.png" class="common_img" />

(3) Attach robot arm to the pan-tilt with M3*6 round-head machine screw.

:::{Note}
The gripper should face towards the front of the car.
:::

<img src="../_static/media/chapter_1/image11.png" class="common_img" />

(4) Connect the wire of pan-tilt servo to the servo on U-shaped bracket.

<img src="../_static/media/chapter_1/image12.png" class="common_img" />

(5) Connect camera cable to USB port of 3D depth camera. Then pass the cable through bracket as pictured. Finally, connect it to port 2 on Jetson Nano board.

<img src="../_static/media/chapter_1/image13.png" class="common_img" />

:::{Note}
For specific wiring instruction, refer to [1.2.4 Wiring Instructions](#anchor_1_2_4).
:::

### 1.2.2 Main Control Board Installation

* **Jetson Nano Control Board**

(1) Mount the control board onto the robot with M2.5*12 double-pass copper columns.

<img src="../_static/media/chapter_1/image14.png" class="common_img" />

(2) Fix the antennas with M2.5*6 round-head machine screws.

<img src="../_static/media/chapter_1/image15.png" class="common_img" />

(3) Fix the expansion board with M2.5*6 round-head machine screws.

<img src="../_static/media/chapter_1/image16.png" class="common_img" />

* **Jetson Orin Nano/Jetson Orin NX Control Board**

(1) Mount the control board onto the robot with M2.5*12 double-pass copper columns.

<img src="../_static/media/chapter_1/image17.png" class="common_img" />

(2) Fix the antennas with M2.5*6 round-head machine screws.

<img src="../_static/media/chapter_1/image18.png" class="common_img" />

(3) Fix the expansion board with M2.5*6 round-head machine screws.

<img src="../_static/media/chapter_1/image19.png" class="common_img" />

* **Raspberry Pi5 Control Board**

(1) Secure the four M2.5*5+6 single-pass nylon columns to the adapter plate using M2.5*6 round head screws.

<img src="../_static/media/chapter_1/image20.png" class="common_img" />

(2) Press down firmly on the push-type screw of the heat sink to mount it on the main board.

<img src="../_static/media/chapter_1/image21.png" class="common_img" />

(3) Attach the main board to the adapter plate using double-pass nylon columns.

<img src="../_static/media/chapter_1/image22.jpeg" class="common_img" />

(4) Insert the expansion board into the pins of Raspberry Pi 5.

<img src="../_static/media/chapter_1/image23.png" class="common_img" />

(5) Attach the adapter plate onto the robot with M2.5*6 round-head screws.

<img src="../_static/media/chapter_1/image24.png" class="common_img" />

### 1.2.3 LCD Screen Installation

* **7-inch LCD Screen Setup**

(1) Install 7-inch LCD screen to columns with M4*6 round-head machine screws.

<img src="../_static/media/chapter_1/image25.jpeg"  class="common_img" />

(2) Connect HDMI cable to HDMI interface on the 7-inch LCD screen, and connect power cable to `CTOUCH` port.

:::{Note}
7-inch LCD screen doesn't support touch control if the cable is not connected to `CTOUCH` port.
:::

<img src="../_static/media/chapter_1/image26.jpeg"  class="common_img" />

<p id="anchor_1_2_4"></p>

### 1.2.4 Wiring Instructions

:::{Note}
Upon receiving the robot, it is necessary to follow the wiring tutorials below to connect the control board. Each accessory must be properly connected to its corresponding port; otherwise, the robot's functions will not work properly.
:::

* **Jetson Nano Controller Wiring**

Please refer to the table below and connect each accessory to its corresponding port on Jetson Nano board. If any of the listed accessories are not included in your kit, please ignore the corresponding port number.

<img src="../_static/media/chapter_1/image27.png"  class="common_img" />

| **NO.** | **Name** |
|:--:|:--:|
| 1 | Jetson Nano board supply interface (DC round head cable) |
| 2 | Display HDMI interface |
| 3 | Depth camera port |
| 4 | USB hub Communication interface |
| 5 | STM32 controller |
| 6 | Display power supply port |
| 7 | Lidar port |
| 8 | Reserved custom expansion interface |
| 9 | Sound card + speaker (For developer kit and ultimate kit only) |
| 10 | Microphone array module (For developer kit and ultimate kit only) |

* **Jetson Orin Nano/Orin NX Controller Wiring**

Please refer to the table below and connect each accessory to its corresponding port on Jetson Orin Nano board and USB hub. If any of the listed accessories are not included in your kit, please ignore the corresponding port number.

<img src="../_static/media/chapter_1/image28.png"  class="common_img" />

| **NO.** | **Name** |
|:--:|:--:|
| 1 | Power supply port of Jetson Orin Nano **(DC round head cable)** |
| 2 | DP interface of 7-inch display |
| 3 | Depth camera interface |
| 4 | USB hub communication interface |
| 5 | STM32 controller communication cable |
| 6 | Display Power Supply Interface |
| 7 | Lidar port |
| 8 | Reserved custom expansion interface |
| 9 | Sound card + speaker (For developer kit and ultimate kit only) |
| 10 | Microphone array module (For developer kit and ultimate kit only) |


* **Raspberry Pi 5 Controller Wiring**

Please refer to the table below and connect each accessory to its corresponding port on Raspberry Pi 5 board and USB hub. If any of the listed accessories are not included in your kit, please ignore the corresponding port number.

<img src="../_static/media/chapter_1/image29.png"  class="common_img" style="width:700px;"/>

| **NO.** | **Name** |
|:--:|:--:|
| 1 | Depth camera port |
| 2 | USB hub Communication Interface |
| 3 | STM32 controller communication cable |
| 4 | 7-inch LCD display power cable (not included in the standard kit) |
| 5 | Ethernet interface |
| 6 | Lidar port |
| 7 | Reserved custom interface |
| 8 | Sound card + speaker (not included in the standard and advanced kits) |
| 9 | Microphone array module (not included in the standard and advanced kits) |

<img src="../_static/media/chapter_1/image30.png"  class="common_img" />

| **NO.** | **Name** |
|:--:|:--:|
| 10 | Power supply for ROS main controller (Raspberry Pi) |
| 11 | Micro HDMI interface (connect to the HDMI interface of the 7-inch LCD display) |

## 1.3 Battery and Charging Setup

It is mandatory for the robot to disconnect power cables during transportation, and the battery is not fully charged. Before the first use, users need to connect the battery wires and then proceed with charging. The charging duration is approximately 3 hours. Charging the robot from 10V to 12.3V takes approximately 3 hours.

### 1.3.1 Charging Safety Instructions

* **General Safety Guidelines**

(1) Charge battery with the provided charger. Turn off the switch on the power supply board and never use it while charging

(2) Indicator on charger changes green when it connects to battery but not plugged into a power outlet. Indicator turns green after the battery is fully charged.

(3) Do not directly connect the charger to DC power port of Jetson Nano board, otherwise the board will be burned.

<img src="../_static/media/chapter_1/image31.png" class="common_img" />

(4) Unplug charger in time to avoid overcharging.

(5) If battery voltage drops below 10V, the buzzer will sound an alarm. Please charge the battery promptly.

(6) In case robot won't be used in a long period of time, please fully charge battery first, then disconnect battery wires.

(7) Always keep battery in cool and dry environment, otherwise battery lifespan gets shortened. Never intentionally hit, throw or step on your Lipo battery.

(8) Avoid using the battery in environments with strong static electricity or a strong magnetic field, as this may damage the safety protection device of the battery.

(9) Do not plug the battery into a power outlet, and do not use metal objects to connect the positive and negative poles of the battery.

(10) If robot won't be used in a long period of time, please fully charge battery.

(11) It is strictly prohibited to modify, weld, or convert battery charger or Lipo battery.

(12) Keep battery away from high temperature and liquid to prevent overheating, fire and damp, which result in function decline.

:::{Note}
Please strictly follow the guide. Our company is not responsible for any product damage, economic losses and accident caused by improper use.
:::

### 1.3.2 Charging Operation Steps

* **Pre-charging Setup**

(1) Make sure the switch is in the closed position.

<img src="../_static/media/chapter_1/image32.png" class="common_img" style="width:600px;"/>

(2) Connect the battery wires ensuring that each wire matches its corresponding color.

<img src="../_static/media/chapter_1/image33.png"  class="common_img" style="width:600px;"/>

<p style="text-align:center">Mecanum/Tank Chassis Wiring Connection Diagram</p>

<img src="../_static/media/chapter_1/image34.png"  class="common_img" style="width:600px;"/>

<p style="text-align:center">Ackermann Chassis Wiring Connection Diagram</p>

* **Charging Process**

(1) Take out the DC connector of the lithium battery from the side or bottom. Connect the charger to charge the battery.

<img src="../_static/media/chapter_1/image35.png"  class="common_img" style="width:600px;"/>

<p style="text-align:center">Mecanum/Tank chassis Charging Port diagram</p>

<img src="../_static/media/chapter_1/image36.png"  class="common_img" style="width:600px;"/>

<p style="text-align:center">Ackerman chassis charging port diagram</p>

(2) Users can view the charging status by observing the indicator on the charger. The red light indicates that the battery is charging, while the green indicates that the charging is complete.

<img src="../_static/media/chapter_1/image37.png" class="common_img" />

:::{Note}
After the charging is complete, please promptly unplug the charger to avoid overcharging.
:::

## 1.4 First Power-on and System Testing

After the robot installation is finished, this section begins the learning of robot's start-up state and functionality testing of each module. Following by this, you can proceed to the next chapter to learn about the operations for app control and handle control.

For exploring its functionality and viewing the program, you need to connect to the robot's system through the remote connection tool, please refer to the subsequent content under [1.6 Development Environment Setup and Configuration](#anchor_1_6).

### 1.4.1 Usage Guidelines

* **General Operating Guidelines**

(1) To ensure the stable performance of the robot, when the battery voltage is below 10V, charge the robot before proceeding with operations.

(2) Avoid placing the robot at the edge of a high platform to prevent it falling and getting damaged.

(3) Using the robot on a flat platform.

(4) Do not stack the servos on robotic arm to avoid the servo damage due to the motor being stuck when powered on.

(5) Avoid keeping the robotic arm under a high load for an extended period because it can curtail the servo's lifespan or directly damage the servo.

(6) Maintain a certain safety distance from the robot to prevent injury in case of contact after powering on.

* **Testing Prerequisites**

(1) The test should be conducted under the conditions that the wiring is correct, the controller receiver is properly connected, the sound is turned on at the top-right corner of the desktop, and the robot is fully charged.

(2) In terms of Lidar, different Lidar models also have different performances when starting up. The left image below is A1 Lidar and the right is the G4 Lidar:

<p class="common_img" style="text-align:center;">

<img  src="../_static/media/chapter_1/image38.png" style="width:450px;" />

<img  src="../_static/media/chapter_1/image39.png" style="width:450px;" />

</p>

If you choose the ultimate kit with Lidar G4, the Lidar will spin for a few rounds, then stop until the robot boots up successfully.

**For other robot kits with Lidar A1, you need to push the switch to the "**ON**" side. The Lidar will continue to rotate after a short period of time after being turned on.**

<img src="../_static/media/chapter_1/image40.png"  class="common_img" style="width:500px;"/>

### 1.4.2 Robot Startup and Hardware Testing

* **Power-on Sequence**

(1) Press the switch at right side of the robot.

<img src="../_static/media/chapter_1/image41.png"  class="common_img" style="width:500px;"/>

(2) The blue LED1 on the expansion board will light up and keep blinking. At this moment, only the network configuration service is enabled, but ROS and other services have not yet completed this process. Wait for **a short "Beep"** from the buzzer to indicate that the device has started.

**The LED indicator for Jetson Nano, Jetson Orin Nano and Jetson Orin NX versions is as pictured:**

<img src="../_static/media/chapter_1/image42.png"  class="common_img" />

**The LED indicator for Raspberry Pi5 version is as pictured:**

<img src="../_static/media/chapter_1/image43.png"  class="common_img" />

(3) After robot boots up successfully, robot is default to AP direct connection mode and generates a WiFi starting with **"HW"**. The initial WiFi password is **"hiwonder"**.

<img src="../_static/media/chapter_1/image44.png" class="common_img" />

* **WiFi Troubleshooting**

:::{Note}
If you cannot find the generated WIFI, please troubleshoot from the following:

* Follow above three steps in **"Robot Startup State & Testing Instruction"** for troubleshooting.
* If the LED1 on expansion board is flashing blue and keeps on, it may be set to LAN mode. In this case, please press and hold the Key1 button for 5-10 seconds. If LED1 starts flashing, indicating that a WI-Fi starting with **"HW"** is generated.
* If the KEY1 button doesn't start flashing after the above operation, SD card or SSD may not be detected, try re-inserting the SD card or SSD.
* If the LED1 on expansion board always remains on after re-inserting the SD card or SSD, it may indicate an issue with the SD card or SSD.
* If you have completed all five steps above and the issue persists, it may lie with Raspberry Pi board or Jetson board. Please reach out to our support team via email at support@hiwonder.com for further assistance.

:::

(4) After the 7-inch display is installed, it will display the system image after the robot starts up. If you're the user of advanced kit or ultimate kit, you will also hear a **"I'm ready"** broadcast.

<img src="../_static/media/chapter_1/image45.png" class="common_img" />

* **Hardware Module Testing**

Please refer to the below table to test the hardware modules:

| **Module** | **Operation** | **Outcome** |
|:--:|:--:|:--|
| LED on expansion board | Observe the LED status | The robot is set to AP direct connection mode by default. The flashing blue LED indicated that the network service configuration has been completed. |
| Buzzer | Examine the short beep | A short beep from the buzzer indicates that the onboard hardware of the expansion board are functional. |
| Lidar | Observe the rotation status | Lidar model: (1) Lidar G4: Upon initial startup, it will rotate for a few rounds, then stop. After the robot startup is complete, it resumes rotating. (2) Lidar A1: it will keep rotating after a brief wait following startup. |
| 7-inch HD touch screen | Tap the icons on system desktop to confirm: (1) Whether the HDMI cable is connected normally. (2) Whether the power cable is connected to the C-TOUCH interface of the screen. | The screen can display the system desktop and can be touched normally. |
| KEY1 button on expansion board | Switch the network status | After connecting to STA LAN mode via app, long press KEY1 and then check if LED1 indicator flashes. |
| Microphone, sound card, speaker | After turning on the robot, say **"Hello, Hiwonder"**. | The robot responds **"I'm here"**. (the voice function is only targeted for the user who purchased advanced kit and ultimate kit.) |
| Depth camera + robotic arm | (1) Connect to the robot via app. (2) Open **"Robot Control"** to view the live camera feed from the depth camera. (3) Swipe the screen to simultaneously control the servo on the pan-tilt. (4) Slide the robot arm control buttons for controlling each joint's servo. | Display the live camera feed and rotate. |
| STM32 controller + DC encoder geared motor | After robot powers on, perform the **"Robot control"** function on app using the wireless handle or mobile phone to check the hardware functions. | Robot is able to operate normally. |

## 1.5 APP Control

Users can control the robot via the app **WonderAi**, and experience the AI vision features. This section will elaborate the operation instructions for each function in the app.

:::{Note}
If you have purchased the robot kit without Jetson or Raspberry Pi board, please first go through the content from [1.6 Development Environment Setup and configuration](#anchor_1_6)to [1.6.7 Robot Version Configuration Tool Instruction](#anchor_1_6_7).
:::

### 1.5.1 APP Installation

:::{Note}
* Please ensure all permissions are granted for the APP, otherwise certain app functions may be affected or unavailable.
* Turn on location and Wi-Fi before using the APP.
:::

(1) APP Installation Pack (Android): [WonderAi](https://play.google.com/store/apps/details?id=com.hiwonder.wonder_ai)

(2) APP Installation Pack (iOS): [WonderAi](https://apps.apple.com/cn/app/wonderai/id1561134103)

<img src="../_static/media/chapter_1/image46.png" class="common_img" style="width:400px"/>

### 1.5.2 Connection Mode Introduction

There are two network modes, including AP direct connection mode and STA LAN mode.

(1) **AP direct connection mode**: Jetson Nano generates a WiFi which can be connected by phones. This WiFi has no internet access.

(2) **STA LAN mode**: Jetson Nano actively connects to specific WiFi. You can access Internet in this mode.

:::{Note}
The default connection mode is AP direct connection mode. Whether you choose AP direct connection mode or STA LAN mode, robot performs the same.

It is recommended to experience robot games under Direct Connection Mode.
:::

### 1.5.3 Direct Connection Setup

:::{Note}
iOS system requires version 11.0 or above, and Android system requires 5.0 or above.

Special attention for Android users: Please ensure all permissions are granted for the APP, otherwise certain app functions may be affected or unavailable.
:::

This section will take the app of Android system to control JetRover mecanum version as an example. The same operations apply to iOS system.

(1) Open **"WonderAi"** APP, then tap **"Advanced"** → **"JetRover(Mecanum)"** in sequence.

:::{Note}
**"JetRover (Track)"** for tank chassis version, and **"JetRover(Acker)"** for Ackerman chassis version.
:::

<img src="../_static/media/chapter_1/image47.png" class="common_img" />

(2) Click **"+"** button, and select **"Direct Connection Mode"**.

<img src="../_static/media/chapter_1/image48.png" class="common_img" />

(3) Click **"Go to connect device hotspots"** to join the WiFi generated by JetRover.

<img src="../_static/media/chapter_1/image49.jpeg" class="common_img" />

(4) The device WiFi starts with **"HW"** and the password is **"hiwonder"**.

<img src="../_static/media/chapter_1/image50.png" class="common_img" style="width:400px"/>

:::{Note}
For iOS user, please do not return back to the APP until the WiFi icon <img src="../_static/media/chapter_1/image51.png" width="70px" /> appears above, otherwise JetRover cannot be searched. If JetRover cannot be searched, please click <img src="../_static/media/chapter_1/image52.png" width="70px" /> to refresh.
:::

(5) Return to the APP, and click the robotic icon to enter home interface.

<img src="../_static/media/chapter_1/image53.png" class="common_img" />

**If you are informed of "No Internet Connection. Whether to keep connection", just select "Keep Connection".**

(6) After clicking on the robot icon, the mode selection interface is as pictured:

<img src="../_static/media/chapter_1/image55.png" class="common_img" />

<p id="anchor_1_5_4">

### 1.5.4 LAN Mode Connection

(1) Firstly, join 5G network, for example **"Hiwonder_5G"**. (The router supporting dual-frequency will distinguish the Wi-Fi name by default under the situation that 2.4 G and 5G are separated. For example, Wi-Fi **"Hiwonder"** is 2.4 frequency band while **"Hiwonder_5G"** is 5G frequency band)

<img src="../_static/media/chapter_1/image56.png" class="common_img" style="width:400px"/>

(2) After connection, open WonderAi. Then click **"Advanced"** → **"JetRover (Mecanum)"** in sequence.

:::{Note}
**"JetRover (Track)"** for tank chassis version, and **"JetRover(Acker)"** for Ackerman chassis version.
:::

<img src="../_static/media/chapter_1/image57.png" class="common_img" />

(3) Click **"+"** button at the lower right corner, then select **LAN Mode**.

<img src="../_static/media/chapter_1/image58.png" class="common_img" />

(4) Continue, enter the Wi-Fi password. Having entered the password, click **"OK"**. Please ensure the password you enter is correct.

<img src="../_static/media/chapter_1/image59.png" class="common_img" />

(5) Click **"Go to connect device hotspots"**.

<img src="../_static/media/chapter_1/image60.png" class="common_img" />

(6) Join the WiFi starting with HW, and input the password **"hiwonder"**. After connection, return back to the APP interface.

<img src="../_static/media/chapter_1/image61.png" class="common_img" />

(7) At this point, WonderAi APP is connecting to the robot.

<img src="../_static/media/chapter_1/image62.png" class="common_img" />

(8) After a while, the robotic icon will show up. And at the same time, LED1 on the expansion board will light up.

<img src="../_static/media/chapter_1/image53.png" class="common_img" />

(9) By long pressing the robotic icon, you can check the IP address and ID.

<img src="../_static/media/chapter_1/image63.png" class="common_img" />

(10) Input this IP address in the search bar on remote desktop software. Then you can enter the robot system desktop. For how to operate, please refer to [1.6 Development Environment Setup and configuration](#anchor_1_6).

(11) If you want switch back to Direct Connect Mode, press KEY1 button on Jetson Nano expansion board until blue LED flashes, which means the current mode is Direct Connect Mode.

### 1.5.5 APP Control Functions

There are 6 games on APP, including robot control, lidar, object tracking, Intelligent patrolling, gesture control, and AR.

<img src="../_static/media/chapter_1/image64.png" class="common_img" />

The brief instruction for each game is shown in the table below:

| **Icon** | **Game** | **Instruction** |
|:--:|:--:|:--:|
| <img src="../_static/media/chapter_1/image65.png" width="70px"/> | Robot Control | Control the movement of the robot. |
| <img src="../_static/media/chapter_1/image66.png" width="70px" /> | Lidar | There are three lidar functions, including avoid obstacle, lidar following and lidar guarding. |
| <img src="../_static/media/chapter_1/image67.png" width="70px"/> | Object Tracking | Select the color for the target, allowing the robot to track the target. |
| <img src="../_static/media/chapter_1/image68.png" width="70px" /> | Line Following | Pave the line, choose the line color as the recognizable color and the robot will move along the line. |
| <img src="../_static/media/chapter_1/image69.png" width="70px" /> | Gesture Control | Control the robot's movement through the movement trajectory of the palm such as, forward and backward, left and right turns, left and right translations (mecanum chassis only) |

### 1.5.6 Robot Control Function

* **Mecanum/Tank Chassis Version Interface**

Tap **"Remote Control"** in the game selection interface to enter the operation interface. **The interface is as follow:**

<img src="../_static/media/chapter_1/image70.png" class="common_img" />

(1) The buttons on the left, from top to bottom, are gravity control button, robot's movement control and speed adjustment slider.

(2) The middle is the live camera feed (you can swipe the screen to rotate the camera's pan-tilt).

(3) The buttons on the right, from top to bottom, are left and right turn control buttons and pan-tilt rotation control buttons.

(4) The icons in the top menu bar are respectively <img src="../_static/media/chapter_1/image71.png" width="70px"  /> for robotic arm control, <img src="../_static/media/chapter_1/image72.png" width="70px" /> screenshot, <img src="../_static/media/chapter_1/image73.png" width="70px"  /> close menu bar, switch to full-screen mode (this function is usually used with wireless controller).

* **Ackerman Chassis Version Interface**

Tap **"Remote Control"** in the game selection interface to enter the operation interface. **The interface is as follow:**

<img src="../_static/media/chapter_1/image74.png" class="common_img" />

(1) The buttons on the left from top to bottom are forward and backward, speed adjustment.

(2) The middle is the live camera feed (you can swipe the screen to rotate the camera's pan-tilt).

(3) The buttons on the right, from top to bottom, are left and right turn control buttons and pan-tilt rotation control buttons.

(4) The icons in the top menu bar are respectively <img src="../_static/media/chapter_1/image71.png"  width="70px" /> for robotic arm control, <img src="../_static/media/chapter_1/image72.png" width="70px" /> screenshot, <img src="../_static/media/chapter_1/image73.png" width="70px" /> close menu bar, switch to full-screen mode (this function is usually used with PS2 wireless handle).

* **Robotic Arm Control Interface**

(5) Tap <img src="../_static/media/chapter_1/image75.png" width="70px" />to display the control panel for each servo of the robotic arm. It allows the robot to be controlled

<img src="../_static/media/chapter_1/image76.png" class="common_img" />

### 1.5.7 Lidar Functions

:::{Note}
* Before starting the game, please place the robot on a flat surface to ensure an enough space for the operation.
* In **"Avoid obstacle"** and **"Lidar following"**, the robot has a detection range of a 90 degrees sector in front.
* JetRover Ackerman chassis version does not support **"Lidar guarding"** function.
* The obstacle height must be greater than the car body.
:::

* **Avoid Obstacle**

When detecting the obstacle, the robot will turn automatically to avoid the obstacle.

* **Lidar Following**

When detecting the obstacle, the robot will adjust its posture to keep a certain distance between it and the obstacle.

* **Lidar Guarding**

After the game starts, JetRover will adjust its body to face the obstacle when detecting the obstacle.

<img src="../_static/media/chapter_1/image77.png" class="common_img" />

### 1.5.8 Target Tracking Function

:::{Note}
* Place the object and the robot on the same surface, and move the object in a translational manner to achieve a better performance.
* Choose a moderate color range, not too large or too small. If the range is too large, it may include colors outside the target; if too small, the target may be easily lost. Additionally, do not allow objects with colors similar to the target to appear in the camera view.
:::

(1) Tap **"Object tracking"** in the game selection interface to access its operation interface. Here, we use a red block for demonstration. Tap **"Pick"** button.

<img src="../_static/media/chapter_1/image78.png" class="common_img" />

(2) Firstly, click **"pick"**, then drag the red circle on the camera returned image to the target to extract the color.

<img src="../_static/media/chapter_1/image79.png" class="common_img" />

(3) After clicking **"OK"**, the **"selected color"** box will display the color.

<img src="../_static/media/chapter_1/image80.png" class="common_img" />

(4) Click **"Start"** button. When moving the target object, JetRover will move following the object.

<img src="../_static/media/chapter_1/image82.png" class="common_img" />

### 1.5.9 Line Following Function

:::{Note}
* Before starting the game, please pave the track using a tape and place the robot on the track.
* The color picking range should not be moderate. If the range is too large, the color outside the target will also be selected. If the range is too small, it will be easy to lost the target. Additionally, please do not have any objects in the camera's field of view that are similar in color to the target.
:::

(1) Click **"Line Following"** on the mode selection screen to enter the operation interface. A red tape is used as a line for demonstration. Tap **"Pick"** button to pick the line color.

<img src="../_static/media/chapter_1/image83.png" class="common_img" />

(2) Drag the red circle on the camera returned image to the path to pick the color, then click **"Pick color"**.

<img src="../_static/media/chapter_1/image84.png" class="common_img" />

(3) Next click **"Confirm"** button. The color you pick will display at the right box.

<img src="../_static/media/chapter_1/image85.png" class="common_img" />

<img src="../_static/media/chapter_1/image86.png" class="common_img" />

(4) Lastly, click **"Start"** button, then the robot will move along the path.

<img src="../_static/media/chapter_1/image87.png" class="common_img" />

### 1.5.10 Gesture Control Function

:::{Note}
* This game supports the right hand.
* During the recognition, it is necessary to appear the entire palm within the camera's field of view.
* Please move the hand at a moderate speed, do not too fast.
:::

(1) Click **"Gesture Control"** at the mode selection interface to enter the operation interface of this game.

(2) Click **"Start"** and follow the instructions for this game. Once the gesture movement trajectory is recognized, the robot will move accordingly.

<img src="../_static/media/chapter_1/image89.png" class="common_img" />

### 1.5.11 AR Function

Place a random tag within the camera's field of view and select any 3D image option on the right. Take **"bicycle"** in here. The three-dimensional image of a bicycle will be displayed at the location of the tag.

<img src="../_static/media/chapter_1/image90.png" class="common_img" />

<p id="anchor_1_6"></p>

## 1.6 Development Environment Setup and Configuration

### 1.6.1 Remote Connection Tool Introduction & Installation

Regarding the two methods of remote control for the robot: graphical and command-line control.

NoMachine and VNC are graphical remote control software. After installation, you can directly control the robot on the computer by connecting to the robot's hotspot. For the Jetson Nano, Jetson Orin Nano, and Jetson Orin NX main controllers, NoMachine is used for connection, while the Raspberry Pi 5 main controller uses VNC. With these two software options, users can clearly see the robot's system desktop, making it easier to operate intuitively.

In contrast to NoMachine and VNC, MobaXterm is an SSH connection that focuses more on command-line control. It does not display the full desktop of the robot system, only a command-line window. For users who are familiar with command-line operations, MobaXterm allows quicker control of the robot via commands while reducing computational load and memory usage.

MobaXterm also has a built-in lightweight X11 server that can directly display graphical application interfaces. Regardless of which control board you use, MobaXterm's SSH connection method is applicable.

In short, NoMachine and VNC are suitable for scenarios that require intuitive operation, while MobaXterm is better for quickly executing commands. Choose the software that best fits your remote control needs.

:::{Note}
Before operation, users with desktop computers should prepare a wireless network card that supports the 5G frequency band.
:::

### 1.6.2 NoMachine Installation

:::{Note}
This tool is applicable to Jetson controller versions.
:::

(1) Enter the same directory as this document to open the installation package nomachine_8.4.2_10_x64 in the folder [Appendix -> 2. Remote Connection Tool](resources_download.md).

(2) Click **"Next"**.

<img src="../_static/media/chapter_1/image91.png" class="common_img" />

(3) Then click **"I accept the agreement"** in the prompt box, and set the **"Language"** as **"English"**, then click **"Next"**.

<img src="../_static/media/chapter_1/image92.png" class="common_img" />

(4) Remain the default installation path. Click **"Next"**.

<img src="../_static/media/chapter_1/image93.png" class="common_img" />

<img src="../_static/media/chapter_1/image94.png" class="common_img" />

(5) Click **"Yes"** to restart the computer (**Please do not skip this step**).

<img src="../_static/media/chapter_1/image95.png" class="common_img" />

<p id="anchor_1_6_3"></p>

### 1.6.3 VNC Installation

:::{Note}
This tool is applicable to Raspberry Pi 5 version.
:::

Enter the same directory as this document to open the installation package **"VNC-Viewer-6.17.731-Windows"** in the folder ["**Appendix -> 2. Remote Connection Tool**"](resources_download.md). In the pop-up dialog box, select **'English'** as the installation language and click the **'OK'** button.

<img src="../_static/media/chapter_1/image96.png" class="common_img" />

(1) Click **"Next"**.

<img src="../_static/media/chapter_1/image97.png" class="common_img" />

(2) Then click **"I accept the agreement"** in the prompt box, and continue.

<img src="../_static/media/chapter_1/image98.png" class="common_img" />

(3) Click **"Install"**.

<img src="../_static/media/chapter_1/image99.png" class="common_img" />

(4) Click **"Finish"** to complete the installation.

<img src="../_static/media/chapter_1/image100.png" class="common_img" />

(5) Once VNC is connected, simply click-on <img src="../_static/media/chapter_1/image101.png"  /> to access it.

### 1.6.4 MobaXterm Installation

:::{Note}
This tool is applicable to any robot version.
:::

(1) Locate the **MobaXterm** installation package in this folder ['2.Appendix->2. Remote Connection Tool'](resources_download.md).

<img src="../_static/media/chapter_1/image102.png" class="common_img" />

(2) Click **"Next"**.

<img src="../_static/media/chapter_1/image103.png" class="common_img" />

(3) Then click **"I accept the agreement"** in the prompt box, and click **"Next"**.

<img src="../_static/media/chapter_1/image104.png" class="common_img" />

(4) Keep the default installation position,and click **"Next"**.

<img src="../_static/media/chapter_1/image105.png" class="common_img" />

(5) Click **"Install"**.

<img src="../_static/media/chapter_1/image106.png" class="common_img" />

<img src="../_static/media/chapter_1/image107.png" class="common_img" />

### 1.6.5 AP Direct Connection Mode Operations

**AP Direct Connection mode: The development board can generate a hotspot that can be connected to by your phone (it cannot access the external network).**

* **Establish Connection via NoMachine**

(1) The robot is set to AP direct connection mode by default. After booting up successfully, it will create a hotspot starting with **"HW"**. As the picture shown below, the connection password is **"hiwonder"**.

<img src="../_static/media/chapter_1/image108.png" class="common_img" />

(2) Open NoMachine, input the IP address **"192.168.149.1"** in the search bar in AP mode, and click **"Configure connection to new host 192.168.149.1"**.

<img src="../_static/media/chapter_1/image109.png" class="common_img" />

(3) After opening, follow these steps: click on **Address -> Name, enter "robot" -> Host, enter "192.168.149.1" -> click Add**.

<img src="../_static/media/chapter_1/image110.png" class="common_img" />

(4) Double click on **"Robot"** to open it.

<img src="../_static/media/chapter_1/image111.png" class="common_img" />

(5) **Fill in the provided username and password based on the control board version:**

**Initial configuration for Jetson Nano board:**

`username: hiwonder`, `password: hiwonder`

**Initial configuration for Jetson Orin Nano board:**

`username: ubuntu`, `password: ubuntu`

**Initial configuration for Jetson Orin NX board:**

`username: ubuntu`, `password: ubuntu`

(6) Check the **"Save this password"** box, then click the **Login** button. Below will take **"Jetson Nano"** version as an example:

<img src="../_static/media/chapter_1/image112.png" class="common_img" />

(7) Afterwards, you will see the remote desktop of the Jetson Nano open up.

<img src="../_static/media/chapter_1/image113.png" class="common_img" />

<img src="../_static/media/chapter_1/image114.png" class="common_img" />

<img src="../_static/media/chapter_1/image115.png" class="common_img" />

<img src="../_static/media/chapter_1/image116.png" class="common_img" />

* **Establish Connection via VNC**

(1) Search for and connect to the hotspot starting with **"HW"**, as shown in the following figure. The password for the connection is `hiwonder`.

<img src="../_static/media/chapter_1/image117.png" class="common_img" />

(2) Next, open VNC software. In the VNC Viewer, enter the IP address **"192.168.149.1"** in the search bar in AP mode, and press Enter. If you receive a security warning, click **'Continue'**

<img src="../_static/media/chapter_1/image118.png" class="common_img" />

(3) Wait for the connection window to pop up, then enter the following in order: `Username` -> `Password` -> Click **'Remember password'** -> Click **'OK'**:

`Username: pi`
`Password: raspberrypi`

<img src="../_static/media/chapter_1/image119.png" class="common_img" />

(4) Once connected, the Raspberry Pi's remote desktop will appear as shown in the image below.

<img src="../_static/media/chapter_1/image120.png" class="common_img" />

* **Establish Connection via MobaXterm**

This section takes **"AP Direct Connection"** as an example to illustrate. The same operation method is applicable to LAN mode. You just need to change the IP address.

(1) In the main interface, click **"Session"** on the top right corner to create a session. In the session interface, enter the recorded Raspberry Pi 5 IP address **"192.168.149.1"**, and then click **"OK"**.

<img src="../_static/media/chapter_1/image121.png" class="common_img" />

(2) Choose SSH.

<img src="../_static/media/chapter_1/image122.png" class="common_img" />

(3) Enter the fixed IP address in AP direction connection mode:

**192.168.149.1**

<img src="../_static/media/chapter_1/image123.png" class="common_img" />

(4) As pictured, you need to select the third option.

<img src="../_static/media/chapter_1/image124.png" class="common_img" />

(5) The interface will prompt users to enter the login as and password. It is necessary to fill in the username and password based on the control board version (Below will take Jetson Nano version as an example):

**Initial configuration for Jetson Nano board:**
`username: hiwonder`, `password: hiwonder`

**Initial configuration for Jetson Orin Nano board:**
`username: ubuntu`, `password: ubuntu`

**Initial configuration for Jetson Orin NX board:**
`username: ubuntu`, `password: ubuntu`

**Initial configuration for Raspberry Pi 5 board:**
`username: pi`, `password: raspberrypi`

<img src="../_static/media/chapter_1/image125.png" class="common_img" />

:::{Note}
* The username must be entered in lowercase mode. Even if the username includes uppercase letters during setup, it must be entered in lowercase when logging in.
* The username will be visually displayed. After entering it, press Enter to proceed to the password input.
* The password will not be visually displayed. After entering the password, press Enter to log in.
:::

(6) When the input password is correct, you will get access to the system. The system interface is as pictured:

<img src="../_static/media/chapter_1/image126.png" class="common_img" />

### 1.6.6 LAN Mode Connection

**STA LAN Mode: the development board is able to actively connect to the designated hotspot/WIFI. (It can connect external network)**

:::{Note}
* If you are uncertain how the robot connect the robot to the STA local network and obtains an IP address, it is recommended to connect via the app.
* The system image has made special configurations for WI-FI, so the WI-FI option cannot be directly selected from the menu bar, as shown in the image below. This does not affect the normal operation of the robot. Users can refer to the **"Method to Restore Wi-Fi Option in the Menu Bar"** for the necessary settings.
* This section will use connecting to the **"Hiwonder_5G"** Wi-Fi as an example. Users should refer to the Wi-Fi that you have set up themselves when configuring the local network connection.
:::

* **Establish Connection via NoMachine**

(1) In LAN mode, search for and connect to the Wi-Fi you have set up on the computer, as shown in the image below.

<img src="../_static/media/chapter_1/image127.png" class="common_img" />

(2) Open NoMachine, input the IP address **"192.168.11.134"** in the search bar in AP mode, and click **"Configure connection to new host 192.168.11.134"**.

:::{Note}
If you are unsure the IP address, please refer to [1.5.4 LAN Mode Connection (Optional)](#anchor_1_5_4).
:::

<img src="../_static/media/chapter_1/image128.png" class="common_img" />

(3) After opening NoMachine, change Name to **"Robot"** and click **"add"**.

<img src="../_static/media/chapter_1/image110.png" class="common_img" />

(4) Then double the name **"Robot"**.

<img src="../_static/media/chapter_1/image111.png" class="common_img" />

(5) Fill in the provided username and password based on the control board version:

**Initial configuration for Jetson Nano board:**
`username: hiwonder`, `password: hiwonder`

**Initial configuration for Jetson Orin Nano board:**
`username: ubuntu`, `password: ubuntu`

**Initial configuration for Jetson Orin NX board:**
`username: ubuntu`, `password: ubuntu`

(6) Check the **"Save this password"** box, then click the Login button. Below will take **"Jetson Nano"** version as an example:

<img src="../_static/media/chapter_1/image112.png" class="common_img" />

(7) Afterwards, you will see the remote desktop of the Jetson Nano open up.

<img src="../_static/media/chapter_1/image113.png" class="common_img" />

<img src="../_static/media/chapter_1/image114.png" class="common_img" />

<img src="../_static/media/chapter_1/image115.png" class="common_img" />

<img src="../_static/media/chapter_1/image116.png" class="common_img" />

* **Establish Connection via VNC**

(1) In LAN mode, search for and connect to the Wi-Fi you have set up on the computer, as shown in the image below.

<img src="../_static/media/chapter_1/image127.png" class="common_img" />

(2) Next, open VNC software. In the VNC Viewer, enter the IP address **"192.168.11.134"** in the search bar in LAN mode, and press Enter. If you receive a security warning, click **'Continue'**.

<img src="../_static/media/chapter_1/image129.png" class="common_img" />

(3) Wait for the connection window to pop up, then enter the following in order: `Username` -> `Password` -> Click **'Remember password'** -> Click **'OK'**:

`Username: pi`
`Password: raspberrypi`

<img src="../_static/media/chapter_1/image119.png" class="common_img" />

(4) Once connected, the Raspberry Pi's remote desktop will appear as shown in the image below.

<img src="../_static/media/chapter_1/image120.png" class="common_img" />

* **Establish Connection via MobaXterm**

(1) In the main interface, click **"Session"** on the top right corner to create a session. In the session interface, enter the recorded robot IP address **"192.168.11.134"**, and then click **"OK"**.

<img src="../_static/media/chapter_1/image121.png" class="common_img" />

(2) Choose SSH.

<img src="../_static/media/chapter_1/image122.png" class="common_img" />

(3) Enter the IP address obtained in LAN mode: `192.168.11.134`

<img src="../_static/media/chapter_1/image130.png" class="common_img" />

(4) As pictured, you need to select the third option.

<img src="../_static/media/chapter_1/image124.png" class="common_img" />

(5) The interface will prompt users to enter the login as and password. It is necessary to fill in the username and password based on the control board version (Below will take Jetson Nano version as an example):

**Initial configuration for Jetson Nano board:**

`username: hiwonder`, `password: hiwonder`

**Initial configuration for Jetson Orin Nano board:**

`username: ubuntu`, `password: ubuntu`

**Initial configuration for Jetson Orin NX board:**

`username: ubuntu`, `password: ubuntu`

**Initial configuration for Raspberry Pi 5 board:**

`username: pi`, `password: raspberrypi`

<img src="../_static/media/chapter_1/image125.png" class="common_img" />

:::{Note}
* The username must be entered in lowercase mode. Even if the username includes uppercase letters during setup, it must be entered in lowercase when logging in.
* The username will be visually displayed. After entering it, press Enter to proceed to the password input.
* The password will not be visually displayed. After entering the password, press Enter to log in.

:::

(6) When the input password is correct, you will get access to the system. The system interface is as pictured:

<img src="../_static/media/chapter_1/image126.png" class="common_img" />

<p id="anchor_1_6_7"></p>

### 1.6.7 Robot Version Configuration Tool Instruction

This section will introduce the robot system's built-in version configuration tool, which allows switching between different chassis configurations, Lidar types, camera models, and Chinese/English voice settings.

It is applicable to the following users:

(1) Users who have purchased a robot kit without control board.

(2) Users who have re-flashed the system image.

(3) Users who have replaced other accessories supported by the system, such as switching from a Mecanum wheel chassis to a tracked chassis.

For users who have purchased a complete robot kit with control board, they only need to be aware of the content and do not need to take action. Before learning how to use the tool, you can first confirm the system version configuration based on the control board model you purchased.

* **Tool Introduction and Usage**

(1) Use the NoMachine remote desktop connection tool to connect to the robot. For specific connection methods, refer to section Remote Device Connection.

(2) Once connected to the remote desktop, double-click on <img src="../_static/media/chapter_1/image151.png" style="width:70px" /> or<img src="../_static/media/chapter_1/image152.png"  style="width:63px" /> for robot system configuration.

(3) In the interface, select the desired robot type options, as shown in the red-boxed area in the following image.

<img src="../_static/media/chapter_1/image153.png" class="common_img" />

(4) Users can check your order information to obtain the hardware version. It typically needs to configure the following areas in the tool: `Depth Camera`, `Lidar`, `Machine`, `ASR`. Please refer to the table below. **Keep the other options at their default settings and avoid incorrect operation to prevent issues!**

| **Option** | **Configuration** |
|:--:|:--:|
| **Depth camera** | Dabai/usb_cam |
| **Lidar** | A1/A2/G4/S2L/LD14P |
| **Machine** | JetRover_Mecanum, JetRover_Acker, JetRover_Tank |
| **ASR** | Chinese/English |

(5) For instance, if you need to switch the machine type from Ackerman version to Mecanum version.

<img src="../_static/media/chapter_1/image153.png" class="common_img" />

(6) After selecting, click **Save -> Apply -> Quit** in sequence. It is crucial to follow this order to successfully switch the chassis type.

<img src="../_static/media/chapter_1/image154.png" class="common_img" />

<img src="../_static/media/chapter_1/image155.png" class="common_img" />

(7) Wait for the robot body to emit a **"beep"** sound, indicating that the chassis type switch was successful.

## 1.7 Wireless Handle Control

### 1.7.1 Usage Guidelines

(1) Please first confirm if the handle receiver is already plugged in before starting the robot. Ignore this step if it is already plugged in. (the USB handle receiver has already been inserted into the robot during installing)

(2) When installing the batteries, please distinguish the positive and negative poles of the battery.

<img src="../_static/media/chapter_1/image169.png" class="common_img" />

(3) After powering on the robot, the app auto-start service will be automatically enabled (app service includes handle control service). If this service is not disabled, no more operations require for it, the robot is allowed to be controlled directly after connecting the wireless handle.

(4) Due to the interactivity of the handle control, when multiple robots are in the same field, it's not recommended to use this function to avoid accidental connection and control errors.

(5) After turning on the wireless handle, if it does not connect the robot within 30 seconds, or no operations with the handle within 5 minutes after connecting to the robot, it will automatically enter sleep mode. If you need to wake up the handle, please press **"START"** button to exit the sleep mode.

### 1.7.2 Device Connection

(1) After the robot is powered on, turn on the switch of the handle. At this point, two LED lights (red and green lights) on the handle will blink simultaneously.

(2) Wait for a few seconds, and the robot and handle will be paired automatically. When pairing is successful, the green LED light will remain on, and the red LED light will turn off.

<img src="../_static/media/chapter_1/image170.png" class="common_img" />

### 1.7.3 Button Instructions

The below table will introduce the functions of the buttons and joysticks (take robot as the first person view):

:::{Note}
Gently pushing the joystick in any direction enables low-speed movement.
:::

| **Button** | **Function** | **Instruction** |
|:--:|:--:|:--:|
| START | Stop and restore the robot's body | Short press |
| Push the left joystick up | Move forward | Push |
| Push the left joystick down | Move backward | Push |
| Left push the left joystick | Left translation (mecanum chassis only) | Push |
| Right push the left joystick | Right translation (mecanum chassis only) | Push |
| Left push the right joystick | Steer left (Ackerman chassis only) | Push |
| Right push the right joystick | Steer right (Ackerman chassis only) | Push |

## 1.8 Quick Mapping and Navigation

This section will help you have a quick experience of mapping and navigation functions. No complicated operations are required, users simply click the corresponding icons on the touch screen to perform functions.

The manual mapping requires users to control the movement of the robot using a wireless handle or keyboard. It's recommended you to use wireless handle to control robot if only a single robot appears in the application scenario. If there are multiple robots in the scenario, it's recommended you to a keyboard for control. This is because the wireless handle is interactive, and in environment with multiple robots, it's advisable not to use this function to avoid accidental connections and control errors.

After mapping is complete, the corresponding map is saved. Then, users can activate the autonomous navigation function to view the mapping results. It's important to note that the map opened with the autonomous navigation function will be the last map created. Regardless of which mapping method is used, the newly created map will overwrite the previous one.

### 1.8.1 Preparation for Mapping

Before powering on the robot, it is necessary to ensure that the touch screen is already installed and connected. 

:::{Note}
The power cable of the touch screen needs to connect to the C-Touch interface, otherwise, the touch functionality is ineffective.
:::

<img src="../_static/media/chapter_1/image171.png" class="common_img" />

Next, you need to confirm whether the handle receiver is securely plugged into the USB port of the robot.

:::{Note}
The handle received is already plugged in the USB hub upon receiving the robot.
:::

### 1.8.2 Manual Mapping Operations

* **ROS1 Mapping**

:::{Note}
* This section is applicable to Jetson Nano controller
* In this mode, it's necessary to set up a closed space beforehand on a flat surface. If obstacles are placed, their height should be at least above the radar's horizontal position.
:::

(1) Place the robot inside the constructed space.

<img src="../_static/media/chapter_1/image172.jpeg" class="common_img" />

(2) Click on the screen desktop. Open <img src="../_static/media/chapter_1/image173.png"  />

<img src="../_static/media/chapter_1/image174.png" class="common_img" />

(3) At this time, Several terminals will be opened to run the program simultaneously. Wait for a while at this point.

<img src="../_static/media/chapter_1/image175.png" class="common_img" />

(4) When you see the below interface, it indicated that the function is enabled successfully.

<img src="../_static/media/chapter_1/image176.png" class="common_img" />

(5) Now, let's use control the robot to map using the wireless handle. The function instruction for each button is as follow:

:::{Note}
When using the handling, keep the distance from the robot not too far to avoid disconnection.
:::

| **Button/Joystick** | **Operation** | **Function** |
|:--:|:--:|:--:|
| START | Short press | Exit sleep mode |
| Left joystick | Push forward/backward | Control robot to move forward and backward |
| Left joystick | Push to left/right | Control the movement of left and right translation (Only supported for Mecanum chassis) |
| Right joystick | Push to left | Control robot to turn left |

You can also choose to control the robot using the keyboard, but it's not recommended here. Keyboard control will be introduced in later courses. If you prefer keyboard control, you'll need to connect to the remote desktop and modify the terminal to enable keyboard control.

<img src="../_static/media/chapter_1/image177.png" class="common_img" />

For the remote system desktop connection, please refer to **"[1.6 Development Environment Setup and configuration](#anchor_1_6)"**.

The button instruction for keyboard control is as follow:

| **Buttons** | **Function** | **Instruction** |
|:--:|:--:|:--:|
| W | Move forward | Short press to this button to forward status. Robot will keep moving forward. |
| S | Move backward | Short press to this button to backward status. Robot will keep moving backward. |
| A | Turn left | Long press to interrupt moving forward or backward and make a counter-clockwise turn to the left in place |
| D | Turn right | Long press to interrupt moving forward or backward and make a right turn. |

When the **"W"** or **"S"** key is pressed, the robot will continue moving forward or backward respectively. When the **"A"** or **"D"** key is pressed, the robot will interrupt the forward or backward motion and rotate counterclockwise or clockwise in place respectively. When the **"A"** or **"D"** key is released, the rotation will stop, and the robot will remain stationary.

:::{Note}
Regardless of whether it's a tank robot or a wheeled robot, using keyboard control cannot make the robot perform lateral movement.
:::

(6) After the movement is complete, press the save button in the bottom left corner, and the robot will save the completed map.

<img src="../_static/media/chapter_1/image178.png" class="common_img" />

The standard for a completed map is as follow:

<img src="../_static/media/chapter_1/image179.jpeg" class="common_img" />

(7) After the mapping is complete, if you want to close this function, click interface and tap<img src="../_static/media/chapter_1/image180.png"  />.

* **ROS2 Mapping**

:::{Note}
* This section is applicable to Jetson Orin Nano/Jetson Orin NX and Raspberry Pi 5.
* In this mode, it's necessary to set up a closed space beforehand on a flat surface. If obstacles are placed, their height should be at least above the radar's horizontal position.
:::

(1) Place the robot inside the constructed space.

(2) Click on the screen desktop. Open the SLAM icon.

<img src="../_static/media/chapter_1/image181.png" class="common_img" />

(3) At this time, Several terminals will be opened to run the program simultaneously. Wait for a while at this point.

<img src="../_static/media/chapter_1/image175.png" class="common_img" />

(4) When you see the below interface, it indicated that the function is enabled successfully.

<img src="../_static/media/chapter_1/image176.png" class="common_img" />

(5) Now, let's use control the robot to map using the wireless handle. The function instruction for each button is as follow:

:::{Note}
When using the handling, keep the distance from the robot not too far to avoid disconnection.
:::

| **Button/Joystick** | **Operation** | **Function** |
|:--:|:--:|:--:|
| START | Short press | Exit sleep mode |
| Left joystick | Push forward/backward | Control robot to move forward and backward |
| Left joystick | Push to left/right | Control the movement of left and right translation (Only supported for Mecanum chassis) |
| Right joystick | Push to left | Control robot to turn left |

You can also choose to control the robot using the keyboard, but it's not recommended here. Keyboard control will be introduced in later courses. If you prefer keyboard control, you'll need to connect to the remote desktop and modify the terminal to enable keyboard control.

<img src="../_static/media/chapter_1/image182.png" class="common_img" />

For the remote system desktop connection, please refer to **"[1.6 Development Environment Setup and configuration](#anchor_1_6)"**.

The button instruction for keyboard control is as follow:

| **Button** | **Function** | **Instruction** |
|:--:|:--:|:--:|
| W | Move forward | Short press to this button to forward status. Robot will keep moving forward. |
| S | Move backward | Short press to this button to backward status. Robot will keep moving backward. |
| A | Turn left | Long press to interrupt moving forward or backward and make a counter-clockwise turn to the left in place |
| D | Turn right | Long press to interrupt moving forward or backward and make a right turn. |

When the **"W"** or **"S"** key is pressed, the robot will continue moving forward or backward respectively. When the **"A"** or **"D"** key is pressed, the robot will interrupt the forward or backward motion and rotate counterclockwise or clockwise in place respectively. When the **"A"** or **"D"** key is released, the rotation will stop, and the robot will remain stationary.

:::{Note}
For Mecanum version, using keyboard control cannot make the robot perform lateral movement.
:::

(6) After the movement is complete, press the **"Save Map"** button in the bottom left corner, and the robot will save the completed map.

<img src="../_static/media/chapter_1/image183.png" class="common_img" />

(7) The standard for a completed map is as follow:

<img src="../_static/media/chapter_1/image184.png" class="common_img" />

(8) After the mapping is complete, if you want to close this function, click interface and tap<img src="../_static/media/chapter_1/image185.png"  />.

<img src="../_static/media/chapter_1/image186.png" class="common_img" />

### 1.8.3 Autonomous Mapping

:::{Note}
* This functionality is only applicable to the Jetson Nano controller.
* Once this function is enabled, JetRover will directly start to move. In this case, it requires you to place the robot on a flat surface.
* In this mode, users need to set up a closed space in advance, preferably on a flat surface. If obstacles are set inside the space, the minimum height of the obstacle must be higher than the horizontal position of the Lidar. The robot can stop after completing autonomous mapping in the closed space.

:::

(1) Click the SLAM Automatic to start the autonomous mapping.

<img src="../_static/media/chapter_1/image187.png" class="common_img" />

(2) After opening, the program will automatically run the program in terminal. When the below interface shows up, it indicates that the interface is enabled successfully.

<img src="../_static/media/chapter_1/image188.png" class="common_img" />

(3) After successful startup, the robot will begin to move autonomously and map its surroundings.

(4) When the robot completes autonomous mapping in this closed space, it will stop and automatically save the map.

### 1.8.4 Autonomous Navigation

:::{Note}
* Autonomous navigation will read the most recently created map, whether manually and autonomously built. If both methods are used simultaneously, it will save the last map created.
* If you want to learn about how to save multiple maps, please delve into the content in [4. Mapping and Navigation Courses](4.Mapping_Navigation_Course.md).

:::

* **ROS1 Autonomous Navigation**

:::{Note}
This section is only applicable to the Jetson Nano controller.
:::

(1) Start the robot. Click the Navigation icon to experience the quick navigation function.

<img src="../_static/media/chapter_1/image189.png" class="common_img" />

(2) After opening, the terminal will run the program. When you see the following interface, it indicates that the opening was successful.

<img src="../_static/media/chapter_1/image190.jpeg" class="common_img" />

(3) In the manual bar, **"2D Pose Estimate"** is used to set the initial position of JetRover, **"2D Nav Goal"** is used to set a target point and **"Publish Point"** is used to set multiple target points.

<img src="../_static/media/chapter_1/image191.png" class="common_img" />

(4) Click on <img src="../_static/media/chapter_1/image192.png"  />to select one point by clicking the map interface as the target destination. If you press and drag with the mouse, you can also select the orientation of the robot after it reaches the target point. After the selection is complete, the robot will automatically generate a route and move to the target point. (Note: <img src="../_static/media/chapter_1/image193.png"  /> changes the initial position of the robot on the map and <img src="../_static/media/chapter_1/image192.png"  />is the target point for single-point navigation).

<img src="../_static/media/chapter_1/image194.jpeg" class="common_img" />

(5) Click<img src="../_static/media/chapter_1/image195.png"  />and press the left mouse at a certain point on the map to set it as the destination point. If you need to perform multi-point navigation, please follow the same operation steps to set multiple destination points.

:::{Note}
You need to click **"Publish Point"** once before setting each destination point.
:::

<img src="../_static/media/chapter_1/image196.jpeg" class="common_img" />

(6) After setting the destination point, click **"Start Navigation"** in the bottom left corner to start navigation. During navigation, the robot will automatically avoid obstacles. If need to stop navigation, click **"Stop Navigation"**, and then robot will stop after reaching the destination point.

For example, in the multi-point navigation shown in the above figure, marked as 1, 2 and 3 on the map (take three marks as example). If the robot is traveling between marks 1 and 2, and when you press **"Stop Navigation"**, it will stop moving after reaching mark 2.

(7) If clicking **"Clear Goals"**, all marks will be cleared.

<img src="../_static/media/chapter_1/image197.jpeg" class="common_img" />

* **ROS2 Autonomous Navigation**

:::{Note}
This section is only applicable to Jetson Orin Nano, Jetson Orin NX and Raspberry Pi 5 controllers.
:::

(1) Start the robot. Click the Navigation icon to experience the quick navigation function.

<img src="../_static/media/chapter_1/image198.png" class="common_img" />

(2) After opening, the terminal will run the program. When you see the following interface, it indicates that the opening was successful.

<img src="../_static/media/chapter_1/image199.png" class="common_img" />

(3) In the manual bar, **"2D Pose Estimate"** is used to set the initial position of the robot, **"2D Nav Goal"** is used to set a target point and **"Publish Point"** is used to set multiple target points, **"Nav2 Goal"** is used to set more complex navigation targets, such as specifying a target point, a target pose or a target field.

<img src="../_static/media/chapter_1/image200.png" class="common_img" />

(4) <img src="../_static/media/chapter_1/image193.png"  />changes the initial position of the robot on the map and mark the robot's actual position.

<img src="../_static/media/chapter_1/image201.png" class="common_img" />

(5) Click on <img src="../_static/media/chapter_1/image193.png"   />to select one point by clicking the map interface as the target destination. If you press and drag with the mouse, you can also select the orientation of the robot after it reaches the target point.

<img src="../_static/media/chapter_1/image202.png" class="common_img" />

<img src="../_static/media/chapter_1/image203.png" class="common_img" />

(6) Click <img src="../_static/media/chapter_1/image204.png"  /> in the bottom left corner to enable multiple-point navigation. Then click <img src="../_static/media/chapter_1/image205.png"  /> to set a target point. Hold and drag that point to select the target point direction.

:::{Note}
You need to click **"Nav2 Goal"** once before setting each destination point.
:::

<img src="../_static/media/chapter_1/image206.png" class="common_img" />

(7) After setting the destination point, click **"Start Nav Through Navigation"** in the bottom left corner to start navigation. During navigation, the robot will automatically avoid obstacles.

<img src="../_static/media/chapter_1/image207.png" class="common_img" />

## 1.9 Hardware Introduction

This chapter focuses on the hardware components of ROS robots, including electronic control system, ROS controller, Lidar and depth camera, etc.

### 1.9.1 Hardware System Wiring Diagram

The hardware connection system diagram of the robot based in the mini STM32 controller is shown below. The specific model and ROS controller may vary, and the detailed instructions will be provided in the following content.

* **Jetson Nano Controller Version**

<img src="../_static/media/chapter_1/image208.jpeg" class="common_img" />

* **Jetson Orin Nano Controller Version**

<img src="../_static/media/chapter_1/image209.jpeg" class="common_img" />

* **Jetson Orin NX Controller Version**

<img src="../_static/media/chapter_1/image210.jpeg" class="common_img" />

* **Raspberry Pi 5 Controller Version**

<img src="../_static/media/chapter_1/image211.jpeg" class="common_img" />

### 1.9.2 Electronic Control System Introduction

* **STM32 Controller**

The robot's electronic control system uses a mini STM32 controller (hereafter referred to as the STM32 controller) as the low-level motion controller. It connects multiple DC encoder reduction motors and has a built-in IMU accelerometer and gyroscope sensor. This setup enables the control of the robot's chassis movement and sensor data collection.

The controller uses the `STM32F407VET6` as the main controller, which features ARM's Cortex-M4 core, a 168 MHz main frequency, 512K of on-chip FLASH, 192K of on-chip SRAM, and integrates FPU and DSP instructions. The system block diagram of the STM32F40x/41x series is shown below:

<img src="../_static/media/chapter_1/image212.jpeg" class="common_img" />

The resource layout on the front side of the control board is shown in the diagram below:

<img src="../_static/media/chapter_1/image213.jpeg" class="common_img" />

The control board also provides a schematic diagram, feature an SWD debugging interface, supports USB serial port program download, and enables STM32 programming for secondary development. It offers onboard resources and peripheral example code for users to learn and use conveniently.

* **Power Supply Instruction**

The 11.1V 6000mAh Lithium battery is tailored for the robot, with a charging voltage of 12.6V. It features overcharge protection, overcurrent protection, over-discharge protection, and short-circuit protection.

<img src="../_static/media/chapter_1/image214.png" class="common_img" />

<img src="../_static/media/chapter_1/image215.png" class="common_img" />

Please use the special charger provided in the kit to charge the robot. Users can view the charging status by observing the indicator on the charger. The red light indicates that the battery is charging, while the green indicates that the charging is complete. (Green light when idle, red light when charging, and green light when fully charged)

<img src="../_static/media/chapter_1/image216.jpeg" class="common_img" />

### 1.9.3 Robot Controller

JetRover offers comprehensive support for various ROS controllers, with similar usage methods across controllers. Raspberry Pi 5 uses the Debian 12 system, while the Jetson series runs on the Ubuntu system. Below is a comparison of the controller specifications for Raspberry Pi 5, Jetson Nano, Jetson Orin Nano, and Jetson Orin NX:

<img src="../_static/media/chapter_1/image217.png" class="common_img" />

* **Jetson Nano Version**

<img src="../_static/media/chapter_1/image218.png" class="common_img" />

The robot utilizes Jetson Nano as its ROS controller, consisting of the Jetson Nano board and Jetson expansion board. The motherboard is a compact yet powerful computer capable of running the mainstream deep learning frameworks, providing the computational power required for most artificial intelligence projects.

The expansion board features connections for LEDs and buttons, enabling users to monitor network status through LED flashes and switch network modes using the button. It also includes reserved GPIO and I2C interfaces. **The mainboard is installed with the Ubuntu18.04 system, and establishes the ROS Melodic environment for robot operations. Additionally, the ROS2 Humble environment is deployed within a Docker container.**

* **Jetson Orin Nano Version**

<img src="../_static/media/chapter_1/image219.png" class="common_img" />

The robot is equipped with the Jetson Orin Nano main controller, which comprises a Jetson Orin Nano motherboard and a Jetson expansion board. The motherboard is a compact yet powerful computer that can run mainstream deep learning frameworks, providing the computational power necessary for most artificial intelligence projects.

The expansion board features connections for LEDs and buttons, enabling users to monitor network status through LED flashes and switch network modes using the button. It also includes reserved GPIO and I2C interfaces. **The controller is installed with Ubuntu 22.04 and features the ROS2 Humble environment for robotic operating systems.**

* **Jetson Orin NX Version**

<img src="../_static/media/chapter_1/image219.png" class="common_img" />

The robot is equipped with the Jetson Orin NX 8/16GB main controller, which comprises a Jetson Orin NX motherboard and a Jetson expansion board. Compared to the Jetson Orin Nano 4GB, the Jetson Orin NX 16GB offers faster processing speeds, improved memory read/write speeds, and a fivefold increase in performance.

The expansion board features connections for LEDs and buttons, enabling users to monitor network status through LED flashes and switch network modes using the button. It also includes reserved GPIO and I2C interfaces. **The controller is installed with Ubuntu 22.04 and features the ROS2 Humble environment for robotic operating systems.**

* **Raspberry Pi5 Version**

<img src="../_static/media/chapter_1/image220.png" class="common_img" />

The robot uses a Raspberry Pi 5 as its ROS main controller, which includes the Raspberry Pi 5 controller and a mini expansion board. The controller is a compact yet powerful computer capable of running major deep learning. The mini expansion board adds functionality with LEDs and buttons, allowing users to monitor network status via LED indicators and switch network modes using a mobile phone. It also features reserved GPIO and I2C interfaces for additional expansion.

**The controller operates with the Raspberry Pi Debian12 official system and has a ROS2 environment set up in Docker.**

Overall, the mini expansion board for the Raspberry Pi 5 is stable, energy-efficient, and highly expandable, capable of supporting mainstream deep learning frameworks and meeting the computational needs of most AI applications.

### 1.9.4 Bus Servo

JetRover is equipped with a 6-degree-of-freedom robotic arm, composed of intelligent bus servos and metal components.

<p style="margin:0 auto 24px;width:100%">
<img  src="../_static/media/chapter_1/image221.png" style="width:24%;" />
<img  src="../_static/media/chapter_1/image222.png" style="width:24%;" />
<img  src="../_static/media/chapter_1/image223.png" style="width:24%;" />
<img  src="../_static/media/chapter_1/image224.png" style="width:24%" />
</p>

HTD-35H*3 (robot body) + HTS-20H servo *1 (pan-tilt) + HTS-31H (gripper) + HTD-35H bus servo (wrist)

### 1.9.5 Hall Encoder DC Gear Motor

The Hall speed encoder is a speed measurement module that uses a Hall sensor encoder with a robust magnetic disk, and generates AB two-phase output pulse signals. In this setup, the motor operates at 12V, and the diagram below illustrates the motor used in the robot, along with their pin configurations.

<img src="../_static/media/chapter_1/image225.png" class="common_img" />

<img src="../_static/media/chapter_1/image226.jpeg" class="common_img" />

### 1.9.6 Vision Module

* **Depth Camera**

JetRover uses the Dabai DCW binocular structured light depth camera. The depth image resolution can reach up to 1920×1080@5/10fps, with an average power consumption of less than 1.2W. The terminal only requires a USB2.0 interface to obtain high-precision 3D depth information for backend usage, enabling the robot to perform functions such as perception, obstacle avoidance, and navigation.

On the robot, it is primarily used to implement functions like OpenCV and can also be utilized for deep learning and KCF object tracking, among other visual applications.

<img src="../_static/media/chapter_1/image227.png" class="common_img" />

### 1.9.7 Lidar

Lidar utilizes laser technology to accurately pinpoint the locations. Its applications extend to various scenarios, including the field of robotics, enabling functions such as Lidar obstacle avoidance, following, SLAM mapping, and navigation.

This robot is compatible with different Lidar models, including A1 Lidar and G4 Lidar. Users can choose Lidar versions according to your requirement. Below are listed two types of Lidar:

<img src="../_static/media/chapter_1/image228.png" style="width:450px" class="common_img" />

<img src="../_static/media/chapter_1/image229.png" style="width:450px" class="common_img" />

### 1.9.8 Additional Components

* **Microphone Array Module**

This module is optional in robot kit. It can allow robot to realize voice wake-up and voice control capabilities.

This robot uses the R818 noise reduction board and a ring-shaped six-way microphone array, which features a planar distribution structure composed of six microphones. It is a system that samples and processes the spatial characteristics of the sound field. It can perform sound source localization, suppress background noise, interference, reverberation, and echo, and achieve 360° equivalent sound reception.

<img src="../_static/media/chapter_1/image230.png" class="common_img" style="width:500px"/>

The noise reduction board can suppress background noise, interference, reverberation, and echoes, as shown in the image below:

<img src="../_static/media/chapter_1/image231.png" class="common_img" />



* **7-inch LCD Screen**

<img src="../_static/media/chapter_1/image233.png" class="common_img" />

:::{Note}
The system desktop shown in image is for demonstration purpose only, please rely on the actual product for accuracy.
:::

The 7-inch LCD screen is optional hardware with both display and touch functionalities. In addition to directly display the robot's system desktop, it allows for a quick experience of mapping and navigation function by touching icons on the desktop.

* **PS2 Wireless Controller**

The STM32 control board has USB PS2 wireless handle receiver connected, allowing chassis movement control through a PS2 controller.

<img src="../_static/media/chapter_1/image234.png" class="common_img" />

The handle receiver is connected to the position highlighted in the below red box:

<img src="../_static/media/chapter_1/image235.png" class="common_img" style="width:500px"/>

* **OLED Display Module**

The OLED display module mainly uses 0.91-inch blue light OLED screen, featuring a viewing range, fast respond, stable graphics, high brightness and high resolution. Its driver chip is the `SSD1306`, and by controlling this chip, we can manage the content displayed on OLED module. It is used on robot for displaying WIFI name and voltage information.

<img src="../_static/media/chapter_1/image236.png" class="common_img" />

## 1.10 ROS System Framework

The core of ROS robot mainly consists of two parts. The first part is the chassis, primarily involving the underlying STM32 controller responsible for robot motion control and sensor data acquisition. The second part is the ROS main control unit (Jetson Nano/Jetson Orin Nano/Jetson Orin NX/RaspberryPi5), running the ROS system and relevant functional routine algorithms.

### 1.10.1 ROS Main Control Hardware Connection

The standard connection method requires a power cable and a USB serial cable to communicate with the ROS main controller via the onboard USB serial port. The STM32 requires a power supply of 9-24V, and the ROS main controllers (Jetson Nano and Raspberry Pi 5) can be directly connected to the STM32's power output port (5V) for power supply through the STM32 power input. The Jetson Orin Nano/Jetson Orin NX requires a 12V power supply.

### 1.10.2 ROS Serial Port Communication

Serial communication is a common output and transmission method used in microcontroller development and robot manufacturing. This product also utilizes serial communication to communicate with the upper-level machine, Jetson Nano/Jetson Orin Nano/Jetson Orin NX/Raspberry Pi 5, and the lower-level STM32 controller.

In order to facilitate communication between software tools and various products, Hiwonder has standardized a communication protocol based on hexadecimal data transmission called the RRC Communication Protocol. Subsequent Wonder products use this communication protocol for programming and communication between the upper and lower-level machines.

* **Communication Protocol**

The instruction is written in hexadecimal. If you are unfamiliar with the calculation method, you can refer to the following: use a calculator tool for base conversion. For converting negative numbers and floating-point numbers into hexadecimal, please search for tutorials online

Command format:

| Frame header | Function code | Data length | Parameter | Checksum |
|:--:|:--:|:--:|:--:|:--:|
| 0xAA 0x55 | (uint8_t) Function | (uint8_t) Length | Data | (uint8_t) CRC |

**Frame Header**: Receiving consecutive `0xAA` and `0x55` indicates that a data packet has arrived.

**Function Code**: Indicates the purpose of an information frame.

**Data Length**: Specifies the number of parameters.

**Parameter**: Additional control information required apart from the function instruction.

**Checksum**: Verifies whether the data is correct, using the CRC check method (calculates the CRC value of Function, Length, and Data, taking the lower 8 bits).

* **User Sending Data to Control Board**

The control board already has a dedicated UART-to-USB circuit. Simply connect the `UART3` port to the PC software using a data cable to enable communication. Here, we use LED control as an example.

**LED light control: Command name `PACKET_FUNC_LED`, value 1**

| **Frame header** | **Function code** | **Data length** | **Parameter** | **Checksum** |
|:--:|:--:|:--:|:--:|:--:|
| 0xAA 0x55 | PACKET_FUNC_LED | 7 | Parameter 1:(uint8_t) `led_id` Parameter 2: (uint16_t) On duration (ms) Parameter 3: (uint16_t) Off duration (ms) Parameter 4: (uint16_t) Number of cycles | CRC |

For example,

① Control LED light to blink 5 times, with each blink lasting 100ms on and 100ms off:

| **Frame header** | **Function code** | **Data length** | **Parameter** | **Checksum** |
|:--:|:--:|:--:|:--:|:--:|
| 0xAA 0x55 | PACKET_FUNC_LED | 7 | Parameter 1: 0x01(1) Parameter 2: 0x64 0x00(100) Parameter 3: 0x64 0x00(100) Parameter 4: 0x05 0x00(5) | CRC |

:::{Note}
This is in little-endian mode. For example, the value 5 (decimal) of uint32_t would be written as 0x00 0x05 in little-endian mode, where the lower byte comes first. Therefore, when sending data, it should be written as 0x05 0x00.
:::

* **Control Board Sending Data to User**

**Bus servo data upload: Command name `PACKET_FUNC_BUS_SERVO`, value 5**

In this example, we will upload the bus servo position.

| **Frame header** | **Function code** | **Data length** | **Parameter** | **Checksum** |
|:--:|:--:|:--:|:--:|:--:|
| 0xAA 0x55 | PACKET_FUNC_BUS_SERVO | 5 | Parameter 1: (uint8_t) `servo_id` Parameter 2: (uint8_t) 0x05 (Sub-command) Parameter 3: (int8_t) Success status (0: Success; -1: Failure) Parameter 4: (int16_t) Servo position | CRC |

When a read command is received, the corresponding servo position parameter is read and uploaded to the PC software.

For example,

Upload the angle of servo 5 as 30°, corresponding to a pulse width of 833.

| **Frame header** | **Function code** | **Data length** | **Parameter** | **Checksum** |
|:--:|:--:|:--:|:--:|:--:|
| 0xAA 0x55 | PACKET_FUNC_BUS_SERVO | 5 | Parameter 1: 0x05 (5) Parameter 2: 0x05 (Sub-command) Parameter 3: 0x00 (0 - Success) Parameter 4: 0x41 0x03 (833 in little-endian format) | CRC |

### 1.10.3 System Software Framework

Before starting this section, you need to use NoMachine remote desktop connection software. For detailed instructions, please refer to **"[1.6 Development Environment Setup and configuration](#anchor_1_6)"**.

* **ROS1 Directory and Functional File Introduction**

:::{Note}
This section is only applicable to the Jetson Nano controller.
:::

(1) Click <img src="../_static/media/chapter_1/image237.png"  /> to open the command terminal. Enter the below command, and then press Enter to view each file under the home directory.

```
ls
```

<img src="../_static/media/chapter_1/image238.png" class="common_img" />

The introduction to each folder is shown in the below table:

| **Directory Name** | **Function** |
|:--:|:--:|
| `hiwonder-toolbox` | Wi-Fi management tool |
| `JetRover_software` | Store the software |
| `JetRover_ws` | Workspace (including the function of each game) |
| `Third_party` | Store the functional package, such as the model trained with YOLOv5 |
| `Music` | Store music files |
| `Pictures` | Store picture files |
| `Public` | User custom folder |
| `Templates` | Template folder (custom) |
| `Videos` | Store video files |

(2) Enter the command and press **"Enter"** to access the directory of the functional packages. Then enter **"ls"** to view each file under the directory.

```
cd ros_ws
ls
```

<img src="../_static/media/chapter_1/image239.png" class="common_img" />

The introduction of each folder:

| **Directory/folder** | **Instruction** |
|:--:|:--:|
| `build` | Compilation space, storing the cache generated during compiling |
| `command` | Store the commands for each function |
| `devel` | Store the target file and executable file after compilation |
| `logs` | Store the logs |
| `src` | Store the source code of the function packages |

(3) Enter command and press Enter to access the directory for the function packages. Enter **"ls"** command to view each files under the directory.

```
cd src
ls
```

<img src="../_static/media/chapter_1/image240.png" class="common_img" />

The introduction of each folder:

| **Directory** | **Type** | **Function** |
|:--:|:--:|:--:|
| `hiwonder_app` | App function packages storage directory | Gesture control, Lidar, intelligent line patrolling and other games |
| `hiwonder_interfaces` | Communication interface file directory | ROS message communication and service communication files |
| `hiwonder_slam` | Mapping-related function storage directory | Various algorithms for mapping and map saving |
| `hiwonder_bringup` | System service storage directory | Launch functions such as app and wireless handle control |
| `hiwonder_multi` | Multi-robot combination function directory | Multi-robot mapping, multi-robot navigation, etc |
| `third_party` | Third-party environment function package directory | The ROS function package such as AprilTag, Lidar, depth camera. |
| `hiwonder_calibration` | Calibration parameter adjustment directory | IMU, linear velocity, angular velocity calibration. |
| `hiwonder_navigation` | Navigation-related function storage directory | Publishing navigation points, rviz navigation |
| `xf_mic_asr_offline` | Voice-related storage directory | Voice-controlled games |
| `hiwonder_driver` | Driving file directory | Kinematics, communicate between Jetson Nano board and STM32 |
| `hiwonder_peripherals` | Peripheral setting directory | Including different lidar models, handle control and keyboard control |
| `hiwonder_example` | Game example storage directory | Creative game: gesture control, posture control, color tracking. |
| `hiwonder_simulations` | Simulation storage directory | Gazebo, MoveIt simulation, URDF file |

**Game File Directory Introduction**

Take the game file in "**/ros_ws/src/hiwonder_app**" as example to explain.

(1) Enter the following command to access the game file directory. There are two folders, including "**launch**" and "**scripts**".

```
cd hiwonder_app
ls
```

<img src="../_static/media/chapter_1/image241.png" class="common_img" />

(2) The **"launch"** folder corresponds to the launch files, while the **"scripts"** folder corresponds to the source code of the games.

<img src="../_static/media/chapter_1/image242.png" class="common_img" />

<img src="../_static/media/chapter_1/image243.png" class="common_img" />

The corresponding launch directory and scripts directory in other function packages are similar as well.

* **ROS2 Directory and Functional File Introduction**

:::{Note}
This section is only applicable to Jetson Nano in Docker, Jetson Orin Nano, Jetson Orin NX and Raspberry Pi 5 controller.
:::

**File Directory Introduction**

(1) Click-on <img src="../_static/media/chapter_1/image244.png"  /> to initiate ROS2 command-line terminal. Then input the following command to check the content contained in the directory.

```
ls
```

<img src="../_static/media/chapter_1/image245.png" class="common_img" />

| **File Name** | **Function** |
|:--:|:--:|
| `noetic_ws` | Workspace for bridging with ROS1 |
| `ros2_ws` | Workspace for ROS2 functional play |
| `share` | Directory shared with the main system (**/home/hiwonder/docker/tmp**) |
| `third_party_ros2` | Relevant third-party software libraries |

(2) Next, enter the command to access the ROS2 workspace and check the file directory distribution.

```
cd ros2_ws
```

```
ls
```

<img src="../_static/media/chapter_1/image246.png" class="common_img" />

(3) The table below provides detailed introduction to each folder.

| **File name** | **Function** |
|:--:|:--:|
| `build` | Compilation space, storing cache information during the compilation process |
| `command` | Stores instructions that implement various functions for easy lookup |
| `install` | Stores compiled target files and executable files |
| `logs` | Folder for storing logs |
| `src` | Folder for storing the source code of function packages |

(4) Enter the command and press Enter to go to the robot function package directory and check the files in the src directory.

```
cd src
```

```
ls
```

<img src="../_static/media/chapter_1/image247.png" class="common_img" />

The table below provides an introduction to each folder.

| **Directory Name** | **Type Description** | **Function Description** |
|:--:|:--:|:--:|
| `app` | Directory for storing various game options for the mobile app | Gesture control, radar, line following, etc. |
| `example` | Directory for storing related vision game options | Color sorting, gesture control, waste classification, etc. |
| `interfaces` | Communication interface file directory | ROS message communication and service communication files |
| `slam` | Directory for storing mapping-related gameplay options | Various mapping algorithms, map saving |
| `calibration` | Calibration parameter adjustment directory | IMU, linear velocity, angular velocity calibration, etc. |
| `navigation` | Directory for storing navigation-related gameplay options | Publishing navigation points, RViz navigation, etc. |
| `xf_mic_asr_offline` | Directory for storing voice control game options | Voice control gameplay options |
| `xf_mic_asr_offline_msgs` | Directory for storing voice control game messages | Voice control gameplay directory |
| `peripherals` | External device settings directory | Includes different types of radar, joystick control, keyboard control, etc. |
| `simulations` | Directory for storing simulation files | Gazebo, MoveIt simulation, URDF, etc. |
| `driver` | Driver file directory | Kinematics, communication between Jetson controller and STM32 |

**Introduction to Function File**

The following explains the game files using  `/ros2_ws/src/app ` as an example.

(1) Enter the below command to navigate to the directory containing the game files. The `launch` and `app` folders are included in it.

```
cd app
```

```
ls
```

<img src="../_static/media/chapter_1/image248.png" class="common_img" />

(2) **'launch'** folder contains the launch files, and the **'app'** folder contains the game source codes.

<img src="../_static/media/chapter_1/image249.png" class="common_img" />

<img src="../_static/media/chapter_1/image250.png" class="common_img" />

The corresponding launch directories and app directories (with the same name as the function packages) for other function packages are similar.

## 1.11 STM32 Source Code Development

### 1.11.1 Source Code Introduction

The STM32 controller is used as the robot underlying motion controller for running STM32 code. The robot chassis has already been burned with corresponding code for direct usage.

It supports ISP code updates through the USB serial port and can also be updated or debugged through the SWD interface. As the underlying chassis driver board for the robot, it is primarily responsible for the tasks such as motor PID control, encoder and IMU data acquisition, RGB light control, etc. Various control methods are supported, including PS2 wireless control, app control, and remote control via an RC transmitter. Additionally, it communicates through a serial port with the ROS base layer's chassis control node, receiving target vector velocities from the basic layer and sending the real-time speed, IMU data, and battery voltage data calculated by the odometry. To enhance these functionalities, STM32 controller utilizes the FreeRTOS embedded operating system for software design.

### 1.11.2 Control Process

The principle of various robot control methods is based on varying robot's velocity. Robot's target velocity is obtained by operating inverse kinematics calculation, which is used as input for the motor velocity PID controller. After PID computation, the STM32 timer outputs PWM motor control signals to the motor driver. The motor driver, in turn, controls the motor's rotation. The encoder collects real-time motor speed, providing feedback to the PID controller, thus realizing closed-loop speed control. The flowchart for the robot's STM32 motor control process is illustrated below:

<img src="../_static/media/chapter_1/image251.jpeg" class="common_img" />

:::{Note}
Different robot types have variations. Mecanum wheel require four motors, while tank robots and Ackerman robots require two motors. Additionally, the front wheels of Ackerman robots require a servo for steering.
:::

### 1.11.3 Program Framework

The underlying source code is developed based on FreeRTOS. Unlike interrupt control, RTOS executes tasks in a round-robin fashion, with tasks of higher priority being executed first. Interrupts have a higher priority than task priorities. The robot task allocation is shown in the figure below:

<img src="../_static/media/chapter_1/image252.jpeg" class="common_img" />

The main task of the robot is responsible for robot control, kinematics processing, IMU data acquisition, data transmission matters. Additionally, it also needs to handle the trivial tasks such as battery level management, IMU calibration, buzzer alarming, and other low-frequency management issues.

### 1.11.4 Program Analysis

For more detailed STM32 code instructions, you can go through the source code, which contains very detailed comments.

### 1.11.5 Kinematics Model

The software supports various robot chassis, each mode featuring different motion characteristics.

Mecanum and tank chassis allow for 360-degree omnidirectional movement. They can not move forward and steer but also achieve movement in any direction within a 360-degree plane.

The Ackermann robot steers by controlling the front wheels with a servo.

For detailed explanations of the kinematic models of different robot chassis, you can refer to the relevant documentation tutorials.

* **ROS2 Reference:**

[2. Motion Control Course -\> 2.1 Kinematics Analysis](2.Motion_Control_Course.md#chassis-switching)

[2. Motion Control Course -\> 2.5 Motion Control](2.Motion_Control_Course.md#imu-linear-velocity-and-angular-velocity-calibration)

### 1.11.6 Project Compilation

After writing the program, we need to compile it into machine language so that it can run on the embedded system. Keil5 includes a built-in compiler that can compile the source code into an executable file.

The compiler can generate different target files based on different processor architectures and instruction sets. Additionally, the compiler can perform code optimization to make the generated executable files more efficient and stable. The steps for compiling the project are as follows:

* **Open options for the generated hex file**

(1) In the Keil5 interface, Click the **"Project"** in the menu bar, and then click the **"Options for File 'app.c'"** button.

<img src="../_static/media/chapter_1/image253.png" class="common_img" />

(2) Click the **"Output"** option, check the three red-marked options below, and then click **"OK"**.

<img src="../_static/media/chapter_1/image254.png" class="common_img" />

* **Compile the Project**

(1) In the Keil5 software interface, click the **"Project"** option in the menu bar, and from the drop-down menu, select **"Build Target"** to compile the project, as shown in the image below:

<img src="../_static/media/chapter_1/image255.png" class="common_img" />

(2) You can also click the icon on the toolbar in the interface to compile, as shown in the image below:

<img src="../_static/media/chapter_1/image256.png" class="common_img" />

(3) If the following content appears in the **"Build Output"** window at the bottom of the software, it indicates that the compilation was successful.

<img src="../_static/media/chapter_1/image257.png" class="common_img" />

:::{Note}
If the **"Build Output"** window shows **"Error(s)"** after compiling the project, you need to double-click on the specific line to jump to the corresponding location and make the necessary corrections, then compile again. If **"Warning(s)"** messages appear, you can ignore them.
:::

### 1.11.7 Program Download

After compiling the project, you can download the generated hex file to the **STM32 main control board**. The following hardware and software materials are required:

[Source Code](../_static/source_code/RosRobotControllerM4.zip)

* **Preparations**

**Software**: ATK-XISP (available in ["**Appendix->Firmware Download Software/ATK-XISP.exe**"](resources_download.md))

<img src="../_static/media/chapter_1/image258.png" class="common_img" />

**Hardware**: Type-C data cable, STM32 main control board

The Type-C cable is used to connect the computer and the STM32 main control board.

<img src="../_static/media/chapter_1/image259.png" class="common_img" style="width:400px;"/>

* **Download Steps**

The specific operation steps are as follows, with the example of the program **"RosRobotControllerM4-ros"**:

(1) Hardware Connection

Insert the Type-C cable into the Type-C port on the STM32 control board (as shown in the red box in the image below) and connect it to the USB port on the computer:

<img src="../_static/media/chapter_1/image260.png" class="common_img" />

(2) Initial Settings

Open the **ATK-XISP** software, select the correct **serial port** (Port) in the software, for example, COM22 (which is recognized as starting with USB), and then set the **baud rate (bps)** to **115200**:

<img src="../_static/media/chapter_1/image261.png" class="common_img" />

In the software interface, select **"Run After Programming,"** **"Verify,"** and **"Perform Full Chip Erase Before Programming,"** as shown in the image below:

<img src="../_static/media/chapter_1/image262.png" class="common_img" />

Then choose the following option:

<img src="../_static/media/chapter_1/image263.png" class="common_img" />

(3) Software Flashing

In the **ATK-XISP** software interface, click the button within the red box in the image below, and then select the hex file that needs to be flashed.

<img src="../_static/media/chapter_1/image264.png" class="common_img" />

Click the **"Start Programming"** button to flash the generated hex file onto the STM32 main control board:

<img src="../_static/media/chapter_1/image265.png" class="common_img" />

<img src="../_static/media/chapter_1/image266.png" class="common_img" />

<img src="../_static/media/chapter_1/image267.png" class="common_img" />

The following prompt indicates that the flashing process is complete.

<img src="../_static/media/chapter_1/image268.png" class="common_img" />

:::{Note}
The STM32 main control board comes with pre-installed firmware. You can flash the **RRC_20240702.hex** file located in the [**"Source Code Materials\STM32"**](resources_download.md) folder.
:::

## 1.12 System Image Flashing

### 1.12.1 Preparations

* **Hardware Requirements**

For **Jetson Nano and Raspberry Pi 5** versions, you need to prepare an SD card. (The storage size depends on the size of the image to be flashed. The example below uses a 64GB SD card), a card reader, and a computer (It's recommended to use Windows 10 operating system).

<img src="../_static/media/chapter_1/image269.png" class="common_img" style="width:300px"/>

<img src="../_static/media/chapter_1/image270.png" class="common_img" style="width:150px"/>

For **Jetson Orin Nano and Jetson Orin NX** versions, you need to prepare a SSD (The storage size depends on the size of the image to be flashed), an SSD flasher (to be prepared separately), and a computer (Windows 10 operating system is recommended).

<img src="../_static/media/chapter_1/image271.png" class="common_img" />

<p style="text-align:center">Solid-state driver</p>

* **Software Requirements**

Install the SSD initialization tool (DiskGenius.exe) and the image flashing tool (Win32DiskImager).

:::{Note}
* Before flashing the image, you can use the SSD initialization tool (the compressed file can be found in ["**Appendix->Image Flashing Tools-> SSD Initialization Tool**"](resources_download.md)) to delete any unnecessary partitions on the disk, then proceed with the flashing.
* After the image flashing is complete, multiple independent disk prompts may appear. Do not click **"Format"**; simply cancel the prompts.
:::

<img src="../_static/media/chapter_1/image272.png" class="common_img" />

### 1.12.2 SD Card/SSD Formatting

:::{Note}
If the SD card or SSD is empty, no formatting is required.
:::

(1) Remove the SD card from Jetson Nano or Raspberry Pi 5, and remove the solid-state drive from Jetson Orin Nano or Jetson Orin NX.

**Jetson Nano**

<img src="../_static/media/chapter_1/image273.png" class="common_img" />

**Raspberry Pi5**

<img src="../_static/media/chapter_1/image274.png" class="common_img" />

**Jetson Orin Nano/Jetson Orin NX**

<img src="../_static/media/chapter_1/image275.png" class="common_img" />

(2) Locate the compressed file in ["**Appendix->3 Image Flashing Tools->1. SSD Initialization Tool**"](resources_download.md). After extracting it, use the **DiskGenius.exe** tool to format the SD card or solid-state drive. Be cautious to select the correct drive letter to avoid formatting your computer's drives by mistake.

(3) Once the SD card or solid-state drive is inserted into the computer, you will notice additional drive letters apart from those of your computer.

<img src="../_static/media/chapter_1/image276.png" class="common_img" />

(4) Right-click and select **"Delete All Partitions."**

<img src="../_static/media/chapter_1/image277.png" class="common_img" />

(5) Create a new partition so that the computer can recognize it properly. If a prompt appears, click **"OK"** to proceed, as shown in the image below:

<img src="../_static/media/chapter_1/image278.png" class="common_img" />

(6) Then click **"Save"** to save the modification.

<img src="../_static/media/chapter_1/image279.png" class="common_img" />

(7) Once successful, you will see the information displayed as shown below. This indicates that the SD card/solid-state drive has been successfully formatted.

<img src="../_static/media/chapter_1/image280.png" class="common_img" />

### 1.12.3 Flash Image Process

(1) Open the image flashing tool (**Win32DiskImager**), click <img src="../_static/media/chapter_1/image281.png"  /> to select the image file (the file must be downloaded and extracted by the user; the image shown is for reference only, and the actual image should be used). Set the **"Device"** field to the drive letter of the SD card or solid-state drive, then click the **"Write"** button to begin flashing the image.

<img src="../_static/media/chapter_1/image282.png" class="common_img" />

:::{Note}
The storage path of the image file must not contain any Chinese characters.
:::

(2) If the prompt appears, simply click the **"Yes"** button to proceed.

<img src="../_static/media/chapter_1/image283.png" class="common_img" />

(3) If the prompt **"Write Successful"** appears, the flashing process has been completed successfully. If an error occurs, please disable any firewall or similar software, reinsert the solid-state drive, and repeat the steps in this section.

<img src="../_static/media/chapter_1/image284.png" class="common_img" style="width:350px" />

:::{Note}
After successful flashing, if a prompt asking whether to format the partition appears, you can ignore it.
:::

(4) Wait for the image flashing to complete. Insert the SD card or solid-state drive back into the control board. Once powered on for a short period, the system should boot successfully.